import sys
import boto3
import requests
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

# Initialize Spark and Glue contexts, and Glue job
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

# Define variables
url = "https://drive.usercontent.google.com/download?id=18B6OrcpS5lVc7I-XLFh-g_jfkK1LrwMr&export=download&authuser=0&confirm=t&uuid=4bfa0bbc-d378-4929-8db4-af5b8c89175d&at=AO7h07f-fbUxi4f0zuEtF_Pph2IO%3A1726831628009"  # Update the URL
s3_bucket = "dataprepcapstone"  # Update the S3 bucket name
s3_key = "zippedfile/data.zip"  # Name of the file to store in S3

# Function to download the file from the URL
def download_file(url):
    response = requests.get(url)
    if response.status_code == 200:
        return response.content
    else:
        raise Exception(f"Failed to download file: {response.status_code}")

# Function to upload file to S3
def upload_to_s3(content, bucket, key):
    s3 = boto3.client('s3')
    s3.put_object(Bucket=bucket, Key=key, Body=content)
    print(f"File uploaded successfully to s3://{bucket}/{key}")

# Main logic for downloading and uploading the file
def main():
    # Step 1: Download the file
    file_content = download_file(url)

    # Step 2: Upload the file to S3
    upload_to_s3(file_content, s3_bucket, s3_key)

# Execute main function
if __name__ == "__main__":
    main()

# Commit the Glue job
job.commit()
